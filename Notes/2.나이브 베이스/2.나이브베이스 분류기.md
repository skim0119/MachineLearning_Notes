베이스 룰을 활용한 분류기
=========================

머신러닝에서의 응용
-------------------

베이지안 규칙을 다시 살펴봅시다.

$$ p(c|\vec{x}) = \frac{p(\vec{x}|c)p(c)}{p(\vec{x})} $$

### 왼쪽 항

이 규칙을 자세희 살펴보면, 왼쪽의 $p(c|\vec{x})$ 는 다음과 같이 나타낼 수 있습니다.

-	$\vec{x}$ 라는 특징들이 c라는 분류에 속할 확률

재미있는점은, 왼쪽 값은 보통 우리가 모르는 값, 혹은 물어보는 '질문'에 해당합니다.

1.	이메일 안에 A라는 단어와 B라는 단어가 포함되어 있다면, 이 이메일이 스펨일 확률이 얼마나 될까?
2.	이 환자의 평소 혈압과 1년에 마시는 술의 양, 평소 수면시간을 주어졌을때 간암에 걸릴 확률은 얼마나 될까?
3.	이틀 전에 비가 왔고 오늘도 비가 왔다면, 내일도 비가 올 확률은 얼마나 될까?

여기서 흥미로운 점은 주어진 특징들과 분류 사이에 어떠한 연관이 없어도 된다는 것입니다. 확률적인 접근방식은 순수하게 통계적인 수치에 의존하기 때문에, 이유와 결과 사이에 어떠한 연관성도 기대할 수 없습니다. 예를 들어 다음과 같은 질문도 사실상 가능해진다는 것입니다.

1.	도시의 강수량과 여러 환경지표를 주어졌을때 범죄율은 얼마나 되는가?

### 오른쪽 항

그렇다면 오른쪽에 있는 값들은 무엇을 의미할까요?

-	$p(\vec{x}|c)$ - c에 속한것중 x 의 비율
-	$p(c)$ - 전체에서 c 분류의 비율
-	$p(\vec{x})$ - 전체에서 x 특징들의 비율

쉽게 보이지는 않지만, 위의 값들은 전부 통계로 얻어질 수 있는 값들이라는 것을 알수 있습니다. 위의 질문중 3번을 예로 들어보겠습니다.

> 이틀 전에 비가 왔고 오늘도 비가 왔다면, 내일도 비가 올 확률은 얼마나 될까?

베이지안 룰에 의하면, 위의 질문은 $p(\vec{x}|c), p(c), p(\vec{x})$ 를 구함으로써 계산할 수 있습니다.

특징은 '이틀 전 비'와 '오늘 비'가 될것이고, 분류하고 싶은것은 내일 날씨가 됩니다.

-	p(이틀 전 비, 오늘 비 | 내일 비) - 이를 풀어서 쓰면 비가 온 날 중에 D-3일과 D-1일에도 비가 온 날의 비율입니다. 과거의 날씨를 가지고 충분히 얻어낼 수 있는 값입니다.
-	p(비) - 비가 온 날의 비율. 이 역시 어렵지 않게 찾을 수 있습니다.
-	p(이틀 전 비, 오늘 비) - 3일중 첫쨋날과 마지막 날에 비가 온 비율. 이 역시 어렵지 않게 찾을 수 있습니다.

세 값 모두 기상청에 들어가 쉽게 찾아낼 수 있는 수치입니다.

장점
----

-	베이지안 룰을 활용할때의 가장 큰 장점은 머신러닝이 가벼워진다는 점입니다. 많은 량의 데이터를 주어졌다고 해도 결과적으로 보관하고 있어야 하는 값들은 그 데이터의 통계입니다.
	-	knn같은 경우 모든 데이터를 보관하고 있어야 하며 분류하고싶은 데이터가 주어졌을 때 모든 데이터와 거리를 계산해야 되기 때문에, 계산량과 메모리 측면에서 비효율적입니다.
-	베이지안의 큰 장점중 하나는 이유와 결과에 대해 어떠한 선입견이나 가정을 가지지 않는다는 점입니다. 보통 결과를 예측하기 위해 그 결과에 대한 원인이 무엇인가를 생각해야 하는 경우가 대부분이지만, 베이지안은 특징과 분류가 굳이 연관이 있을 필요가 없습니다.

단점
----

-	선입견과 가정을 가지지 않고 통계에 의지한다는 특징은 가끔씩 단점이 되기도 합니다. 머신러닝을 만들면서 찾아내고싶은 것중 하나는 바로 '연관성'입니다.
	-	어쩌면 주어진 데이터를 옳바르게 분류하는것보다 데어터 간에 연관성, 공통점, 차이점 등 관계를 찾아내는게 주된 목적이 될 수도 있습니다.
	-	베이지안은 단순히 통계적인 측면만 다루기 때문에 연관성이 없는 데이터 마저도 분류하려는 특징이 있습니다.
