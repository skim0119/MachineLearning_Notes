# 회귀

나이브 베이스나 k-근접이웃 방법은 특징들만 비교해서 비슷한 항목을 구별해낸다고 볼 수 있습니다. 이러한 방법은 어떤 특징과 항목 사이에 특별한 관계가 없더라도 주어진 데이터를 분류해낸다는 강력한 장점이 있습니다. 하지만, 만약 명확하게 특징과 항목 사이에 규칙성이 있다면, 이러한 규칙을 활용해 조금 다른 방식의 분류를 할 수 있습니다. 그리고 이러한 규칙을 활용해 데이터의 속성과 분류가 얼마나 밀접하게 관련되있는지를 살펴볼 수 있습니다.

![iris image](images/irissepal.png)

## 특징

| 장점 | 단점 |
|:---:|:---:|
|극한의 데이터에 대해 결과를 낼 수 있다. | 이상치에 대해 민감하게 반응한다  |

회귀(Regression)이란 기본적으로 특징-결과 사이에 규칙성, 혹은 관계를 찾아내는 과정입니다. 머신러닝 뿐만 아니라 다양한 분야에서 어떠한 데이터를 가지고 통계적인 모델링을 할때 사용되는 대표적인 방법입니다.

![regression (unlicensed)](https://cdn-images-1.medium.com/max/600/1*iuqVEjdtEMY8oIu3cGwC1g.png)

다음과 같은 그래프를 자주 볼 수 있습니다. 빨간색 점들은 2가지 다른 변수에 의해 나타낼 수 있는데 데이터를 표기한 것이고, 파란색 선은 이 두가지 변수 사이에 어떠한 관계를 나타내고 있습니다. 이러한 관계를 찾아낸다면, 우리는 수치형 값을 예측할 수 있는 강력한 도구를 가지게 되는 샘입니다. 이러한 '예측'이 주된 목적이 되기도 하지만, 또다른 의미는 과연 두가지 다른 변수가 얼마나 서로 밀접한 관계가 되어있는지를 판단하는 일입니다. 이는 데이터가 찾아낸 회귀 모델 주변에 얼마나 밀집되어있는지로 판단할 수 있습니다.

회귀법을 사용하는 방법은 크게 세가지로 나눠질 수 있습니다. 첫번째 단계는 모델링입니다. 이는 우리가 다루고있는 데이터들의 특징들 사이에 관계(relation)를 먼저 예측해보는 일입니다. 두번째 단계는 우리가 예측한 모델을 주어진 데이터를 가장 잘 나타내도록 맞추는 일입니다. 이 과정을 트레이닝(training), 피팅(fitting), 러닝(learning)등으로 불립니다. 마지막으로, 새로운 미지의 데이터를 우리가 만든 모델에 사용하는 일입니다.

## 회귀의 종류

회귀는 모델과 용도에 따라서 종류가 다양하게 변합니다. 데이터를 반영하는 모양에 따라 선형회귀, 다항회귀, 지수회귀 등으로 불리며, 데이터와 회귀모델 사이에 거리를 측정해 모델을 평가할수 있습니다. 회귀모델을 정했다면, 이 거리를 좁혀나가는 방식으로 최적화합니다. 물론 여러 모델을 동시에 선택해 어느 모델이 더 적합한지를 판단할 수도 있습니다.

먼저, 가장 기본적인 회귀법인 선형회귀를 살펴본 뒤, 머신러닝에 사용되는 로지스틱 회귀를 설명하겠습니다.

### 선형회귀

### 로지스틱회귀 이론
